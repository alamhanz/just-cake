{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kue Dataset - Model1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c conda-forge keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "\n",
    "import scipy.io\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import shutil\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.io import loadmat\n",
    "import random\n",
    "import sklearn\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH_DATA = '../data/'\n",
    "PATH_DATA_IMAGES = '../../dataset257/'\n",
    "PATH_DATA_TRAIN = PATH_DATA_IMAGES+'train/'\n",
    "PATH_DATA_VAL = PATH_DATA_IMAGES+'validation/'\n",
    "PATH_DATA_TEST = PATH_DATA_IMAGES+'test/'\n",
    "PATH_MODEL = '../../tmp/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kue_kastengel',\n",
       " 'kue_dadar_gulung',\n",
       " 'kue_klepon',\n",
       " 'kue_risoles',\n",
       " 'kue_lumpur',\n",
       " 'kue_serabi',\n",
       " 'kue_lapis',\n",
       " 'kue_putri_salju']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(PATH_DATA_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import metrics, optimizers\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "# sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\n",
    "# tf.debugging.set_log_device_placement(True)\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kue_dadar_gulung': 0,\n",
       " 'kue_kastengel': 1,\n",
       " 'kue_klepon': 2,\n",
       " 'kue_lapis': 3,\n",
       " 'kue_lumpur': 4,\n",
       " 'kue_putri_salju': 5,\n",
       " 'kue_risoles': 6,\n",
       " 'kue_serabi': 7}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## label dict\n",
    "lab = [i for i in os.listdir(PATH_DATA_TRAIN) if '.' not in i]\n",
    "lab.sort()\n",
    "\n",
    "label_dict = dict(zip(lab,[i for i in range(len(lab))]))\n",
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_SIZE = len(label_dict.keys())\n",
    "IMAGE_SIZE = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "just_cake_model = Sequential()\n",
    "just_cake_model.add(Conv2D(32, (3, 3), activation ='relu', input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)))\n",
    "just_cake_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "just_cake_model.add(Conv2D(64, (3, 3), activation ='relu'))\n",
    "just_cake_model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "just_cake_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "just_cake_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "just_cake_model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "just_cake_model.add(Dense(512, activation ='relu'))\n",
    "just_cake_model.add(Dense(256, activation ='relu'))\n",
    "# just_cake_model.add(Dropout(0.5))\n",
    "just_cake_model.add(Dense(LABEL_SIZE,activation ='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8)                 2056      \n",
      "=================================================================\n",
      "Total params: 1,332,936\n",
      "Trainable params: 1,332,936\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "just_cake_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compile model\n",
    "opt = optimizers.Adam(learning_rate=0.001)\n",
    "just_cake_model.compile(loss='categorical_crossentropy',\n",
    "              #optimizer='rmsprop',\n",
    "              optimizer = opt,\n",
    "              metrics=['accuracy',metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1516 images belonging to 8 classes.\n",
      "Found 160 images belonging to 8 classes.\n",
      "Found 160 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "## data generator\n",
    "BATCH_SIZE = 128\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        zoom_range=0.2,\n",
    "        rotation_range=35,\n",
    "        width_shift_range=0.25,\n",
    "        height_shift_range=0.25,\n",
    "        shear_range=0.25,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        PATH_DATA_TRAIN,  \n",
    "        target_size=(IMAGE_SIZE, IMAGE_SIZE), \n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode=\"categorical\" )  \n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "        PATH_DATA_VAL,  \n",
    "        target_size=(IMAGE_SIZE, IMAGE_SIZE), \n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode=\"categorical\" )  \n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        PATH_DATA_TEST,\n",
    "        target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode=\"categorical\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "11/11 [==============================] - 43s 4s/step - loss: 2.0271 - accuracy: 0.1888 - auc_1: 0.6044 - val_loss: 1.8077 - val_accuracy: 0.2812 - val_auc_1: 0.7531\n",
      "Epoch 2/250\n",
      "11/11 [==============================] - 36s 3s/step - loss: 1.7742 - accuracy: 0.2860 - auc_1: 0.7437 - val_loss: 1.5950 - val_accuracy: 0.4062 - val_auc_1: 0.8129\n",
      "Epoch 3/250\n",
      "11/11 [==============================] - 35s 3s/step - loss: 1.7123 - accuracy: 0.3098 - auc_1: 0.7670 - val_loss: 1.5873 - val_accuracy: 0.3438 - val_auc_1: 0.8062\n",
      "Epoch 4/250\n",
      "11/11 [==============================] - 43s 4s/step - loss: 1.6314 - accuracy: 0.3786 - auc_1: 0.7948 - val_loss: 1.6207 - val_accuracy: 0.3125 - val_auc_1: 0.7912\n",
      "Epoch 5/250\n",
      "11/11 [==============================] - 52s 5s/step - loss: 1.5536 - accuracy: 0.3904 - auc_1: 0.8142 - val_loss: 1.4360 - val_accuracy: 0.4141 - val_auc_1: 0.8415\n",
      "Epoch 6/250\n",
      "11/11 [==============================] - 36s 3s/step - loss: 1.4481 - accuracy: 0.4347 - auc_1: 0.8445 - val_loss: 1.2444 - val_accuracy: 0.5000 - val_auc_1: 0.8854\n",
      "Epoch 7/250\n",
      " 2/11 [====>.........................] - ETA: 26s - loss: 1.3849 - accuracy: 0.4831 - auc_1: 0.8625"
     ]
    }
   ],
   "source": [
    "## save best model and use early stopping\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',mode='min', patience=50) \n",
    "check_p = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=PATH_MODEL+'just_cake_model_checkpoint0.h5',\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        save_best_only=True)\n",
    "\n",
    "epoch_hist = just_cake_model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=1516 // BATCH_SIZE,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=160 // BATCH_SIZE,\n",
    "        callbacks=[early_stop,check_p],\n",
    "        epochs=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_epoch_hist = pd.DataFrame(epoch_hist.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_epoch_hist[['loss','val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_epoch_hist.to_csv('../artifact/epoch_hist_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# depd = {'auc_1' : metrics.AUC}\n",
    "model_load = load_model(PATH_MODEL + 'just_cake_model_checkpoint0.h5',compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = test_generator.classes\n",
    "predictions = model_load.predict(test_generator)\n",
    "\n",
    "y_true = true_labels\n",
    "y_pred = np.array([np.argmax(x) for x in predictions])\n",
    "\n",
    "cm = sklearn.metrics.confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,8))\n",
    "sns.heatmap(cm, annot= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p37",
   "language": "python",
   "name": "p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
